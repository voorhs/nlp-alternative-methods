# Конспект по нетрансформерным методам NLP

Конспект [тут](./notes.pdf).

> Данная лекция представляет всесторонний обзор State-Space Models (SSMs), прослеживая их эволюцию от фреймворка HiPPO до современной архитектуры Mamba, а также расширяет обсуждение на родственные линейные архитектуры. Мы начинаем с математических основ (полиномиальные проекции, дифференциальные уравнения) и показываем, как они воплощаются в трёх направлениях развития: рекуррентная память HiPPO, структурированные и селективные SSM-слои (LSSL, S4, DSS, S4D, Mamba). Далее рассматриваются линейные трансформеры, демонстрирующие, как идеи внимания переносятся на рекуррентные архитектуры, и сопоставляются с SSM через призму дуальности трансформеров и моделей состояний. Финальный блок посвящён RWKV. На протяжении всего текста подчёркиваются теоретические связи, инженерные компромиссы и практические реализации, позволяющие достигать линейной временной сложности без потери качества на задачах языкового моделирования.

## Исходники

Данный репозиторий содержит исходный `.tex` документ для конспекта по методам State-Space Models и докер контейнер для компиляции латеха с поддержкой кириллических символов. Чтобы скомпилировать документ:

1. Постройте образ (имя `latex-cyrillic` важно):
```bash
cd latex
docker build -t latex-cyrillic .
```

2. Скомпилируйте документ:
```bash
cd ..
./latex/compile.sh latexmk -xelatex notes.tex
```

